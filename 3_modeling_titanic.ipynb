{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Titanic Modeling: Model Comparison & Quick Tuning\n",
        "Notebook ini membandingkan beberapa algoritma klasifikasi umum untuk data Titanic, menggunakan preprocessing yang sesuai (imputasi, one-hot untuk kategori, scaling untuk model yang perlu).\n",
        "\n",
        "- Metrik utama: ROC-AUC (juga lapor Accuracy, F1).\n",
        "- Validasi: Stratified 5-Fold.\n",
        "- Menggunakan DataFrame yang sudah ada di memori jika tersedia (mis. `df`), atau fallback membaca CSV di folder (`Titanic_prepared.csv`, `Titanic_cleaned.csv`, `Titanic_Dataset.csv`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) Setup & Data selection (robust terhadap berbagai nama variabel)\n",
        "import os\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Cari DataFrame yang sudah ada di memori\n",
        "_g = globals()\n",
        "df_candidates = []\n",
        "for _name in ['df_prepared','df_clean','df_model','df','data','titanic_df']:\n",
        "    if _name in _g and isinstance(_g[_name], pd.DataFrame) and len(_g[_name]) > 0:\n",
        "        df_candidates.append((_name, _g[_name]))\n",
        "\n",
        "df_use = None\n",
        "if df_candidates:\n",
        "    # Utamakan yang memiliki kolom target 'survived'/'Survived'\n",
        "    for _name, _df in df_candidates:\n",
        "        if any(c.lower() == 'survived' for c in _df.columns):\n",
        "            df_use = _df.copy()\n",
        "            print(f'Menggunakan DataFrame dari variabel: {_name}')\n",
        "            break\n",
        "    if df_use is None:\n",
        "        df_use = df_candidates[0][1].copy()\n",
        "        print(f'Menggunakan DataFrame dari variabel: {df_candidates[0][0]} (tanpa cek kolom target)')\n",
        "else:\n",
        "    # Fallback: coba baca dari file CSV yang ada\n",
        "    for _path in ['Titanic_prepared.csv','Titanic_cleaned.csv','Titanic_Dataset.csv']:\n",
        "        if os.path.exists(_path):\n",
        "            df_use = pd.read_csv(_path)\n",
        "            print(f'Membaca data dari: {_path}')\n",
        "            break\n",
        "\n",
        "if df_use is None:\n",
        "    raise ValueError('Tidak menemukan DataFrame/CSV. Pastikan data tersedia.')\n",
        "\n",
        "# Tentukan kolom target\n",
        "target_candidates = [c for c in df_use.columns if c.lower() == 'survived']\n",
        "if not target_candidates:\n",
        "    raise ValueError("Kolom target 'survived' tidak ditemukan. Ubah 'target_col' secara manual.")\n",
        "target_col = target_candidates[0]\n",
        "\n",
        "# Siapkan X, y (label encoding jika target non-numerik)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "y_raw = df_use[target_col]\n",
        "if not pd.api.types.is_numeric_dtype(y_raw):\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y_raw)\n",
        "    print('Target diencode (LabelEncoder):', dict(zip(le.classes_, le.transform(le.classes_))))\n",
        "else:\n",
        "    y = y_raw.values\n",
        "\n",
        "X = df_use.drop(columns=[target_col])\n",
        "print('Shape X, y:', X.shape, len(y))\n",
        "\n",
        "# Deteksi tipe kolom\n",
        "num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n",
        "cat_cols = [c for c in X.columns if c not in num_cols]\n",
        "print(f'Numerik: {len(num_cols)} kolom, Kategorikal: {len(cat_cols)} kolom')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) Preprocessor & Kandidat Model\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "def make_preprocessor(scale_numeric: bool):\n",
        "    transformers = []\n",
        "    if num_cols:\n",
        "        num_steps = [('imputer', SimpleImputer(strategy='median'))]\n",
        "        if scale_numeric:\n",
        "            num_steps.append(('scaler', StandardScaler()))\n",
        "        transformers.append(('num', Pipeline(num_steps), num_cols))\n",
        "    if cat_cols:\n",
        "        transformers.append(('cat', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "        ]), cat_cols))\n",
        "    return ColumnTransformer(transformers)\n",
        "\n",
        "# Kandidat model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "candidates = [\n",
        "    ('LogReg', LogisticRegression(max_iter=2000, class_weight='balanced', solver='lbfgs'), True),\n",
        "    ('RandomForest', RandomForestClassifier(n_estimators=400, class_weight='balanced', n_jobs=-1, random_state=42), False),\n",
        "    ('HistGB', HistGradientBoostingClassifier(learning_rate=0.06, max_depth=None, random_state=42), False),\n",
        "    ('GradBoost', GradientBoostingClassifier(n_estimators=300, learning_rate=0.08, random_state=42), False),\n",
        "    ('SVM-RBF', SVC(kernel='rbf', probability=True, class_weight='balanced', C=3.0, gamma='scale', random_state=42), True),\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3) Cross-Validation & Skor\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = {\n",
        "    'roc_auc': 'roc_auc',\n",
        "    'accuracy': 'accuracy',\n",
        "    'f1': 'f1'\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model, needs_scaling in candidates:\n",
        "    pipe = Pipeline([('pre', make_preprocessor(scale_numeric=needs_scaling)), ('clf', model)])\n",
        "    scores = cross_validate(pipe, X, y, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=False)\n",
        "    results.append((name, scores['test_roc_auc'].mean(), scores['test_accuracy'].mean(), scores['test_f1'].mean()))\n",
        "\n",
        "results_sorted = sorted(results, key=lambda x: x[1], reverse=True)\n",
        "print('Model               |  AUC   |  ACC   |   F1')\n",
        "for name, auc, acc, f1 in results_sorted:\n",
        "    print(f'{name:18s}| {auc: .3f} | {acc: .3f} | {f1: .3f}')\n",
        "\n",
        "best_name = results_sorted[0][0]\n",
        "print('\nModel terbaik (berdasarkan AUC):', best_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4) Tuning Cepat untuk model terbaik\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import scipy.stats as st\n",
        "\n",
        "def run_quick_tuning(best_name):\n",
        "    if best_name == 'HistGB':\n",
        "        base = Pipeline([('pre', make_preprocessor(False)), ('clf', HistGradientBoostingClassifier(random_state=42))])\n",
        "        param_dist = {\n",
        "            'clf__learning_rate': st.loguniform(1e-2, 2e-1),\n",
        "            'clf__max_depth': [None, 3, 5],\n",
        "            'clf__max_leaf_nodes': [31, 63, 127],\n",
        "            'clf__min_samples_leaf': [10, 20, 50, 100]\n",
        "        }\n",
        "    elif best_name == 'RandomForest':\n",
        "        base = Pipeline([('pre', make_preprocessor(False)), ('clf', RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced'))])\n",
        "        param_dist = {\n",
        "            'clf__n_estimators': [200, 400, 600],\n",
        "            'clf__max_depth': [None, 8, 12, 16],\n",
        "            'clf__min_samples_leaf': [1, 2, 5],\n",
        "            'clf__max_features': ['sqrt', 0.5, None]\n",
        "        }\n",
        "    elif best_name == 'LogReg':\n",
        "        base = Pipeline([('pre', make_preprocessor(True)), ('clf', LogisticRegression(max_iter=5000, class_weight='balanced'))])\n",
        "        param_dist = {\n",
        "            'clf__C': st.loguniform(1e-2, 1e1),\n",
        "            'clf__solver': ['lbfgs', 'liblinear']\n",
        "        }\n",
        "    elif best_name == 'SVM-RBF':\n",
        "        base = Pipeline([('pre', make_preprocessor(True)), ('clf', SVC(kernel='rbf', probability=True, class_weight='balanced', random_state=42))])\n",
        "        param_dist = {\n",
        "            'clf__C': st.loguniform(1e-1, 1e2),\n",
        "            'clf__gamma': st.loguniform(1e-3, 1e0)\n",
        "        }\n",
        "    elif best_name == 'GradBoost':\n",
        "        base = Pipeline([('pre', make_preprocessor(False)), ('clf', GradientBoostingClassifier(random_state=42))])\n",
        "        param_dist = {\n",
        "            'clf__n_estimators': [200, 300, 500],\n",
        "            'clf__learning_rate': st.loguniform(5e-2, 3e-1),\n",
        "            'clf__max_depth': [2, 3, 4]\n",
        "        }\n",
        "    else:\n",
        "        print('Model terbaik tidak dikenali untuk tuning cepat, lewati.')\n",
        "        return None\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    search = RandomizedSearchCV(base, param_distributions=param_dist, n_iter=20, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=42, verbose=1)\n",
        "    search.fit(X, y)\n",
        "    print('Best AUC:', search.best_score_)\n",
        "    print('Best Params:', search.best_params_)\n",
        "    return search\n",
        "\n",
        "search_result = run_quick_tuning(best_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5) Fit final & Permutation Importance (top-15 fitur)\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "if search_result is not None:\n",
        "    final_model = search_result.best_estimator_\n",
        "else:\n",
        "    # Bangun ulang pipeline terbaik tanpa tuning tambahan\n",
        "    mapping = {n: (m, s) for (n, m, s) in candidates}\n",
        "    m, needs_scaling = mapping[best_name]\n",
        "    final_model = Pipeline([('pre', make_preprocessor(needs_scaling)), ('clf', m)])\n",
        "    final_model.fit(X, y)\n",
        "\n",
        "# Evaluasi CV prediksi untuk laporan ringkas\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "proba = cross_val_predict(final_model, X, y, cv=cv, method='predict_proba', n_jobs=-1)[:,1]\n",
        "pred = (proba >= 0.5).astype(int)\n",
        "print('ROC-AUC (CV):', roc_auc_score(y, proba))\n",
        "print('Confusion Matrix (CV):\n', confusion_matrix(y, pred))\n",
        "print('Classification Report (CV):\n', classification_report(y, pred, digits=3))\n",
        "\n",
        "# Permutation importance langsung di pipeline\n",
        "final_model.fit(X, y)\n",
        "perm = permutation_importance(final_model, X, y, n_repeats=5, random_state=42, scoring='roc_auc')\n",
        "feature_names = []\n",
        "# Ambil nama fitur dari ColumnTransformer (OneHot menghasilkan fitur tambahan)\n",
        "pre = final_model.named_steps['pre']\n",
        "# Numeric names\n",
        "feature_names.extend(num_cols)\n",
        "# OneHot names\n",
        "if cat_cols:\n",
        "    ohe = pre.named_transformers_['cat'].named_steps['onehot']\n",
        "    ohe_names = list(ohe.get_feature_names_out(cat_cols))\n",
        "    feature_names.extend(ohe_names)\n",
        "\n",
        "imp = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance_mean': perm.importances_mean,\n",
        "    'importance_std': perm.importances_std\n",
        "}).sort_values('importance_mean', ascending=False)\n",
        "print('Top-15 fitur (Permutation Importance):')\n",
        "display(imp.head(15))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

